---
title: "Multi-label Classification of Tracks" 
date: 2022-05-15
order: 1
show_date: false
url: /multi_label_classification_tracks/
aliases: 
    - /multi_label_classification_tracks.html
tags: ["Classification", "Multi-label", "Audio"]
author: "Mélissa Tamine, in a group work"
summary: " The project aimed to build a performing model associating genre labels with each music title in a database using audio signal data and listener-related information, operating within a multi-label classification framework." 
cover:
    image: ""
    alt: ""
    relative: true
editPost:
    URL: "https://github.com/taminemelissa/multi-label-classification"
    Text: "GitHub"

---

---

##### Links

+ [GitHub](https://github.com/taminemelissa/multi-label-classification)
+ [Final report](/projects/memoire_statistique_appliquee.pdf)

---

##### Abstract

Music recommendation systems are pivotal in the escalating success of online music platforms. These systems, tailored for individual users, rely on two strategies: recommendations based on a user's listened song components or on choices made by similar users [1]. Among these musical components, genre stands out as crucial, both for system construction and music classification. Despite challenges in genre definition and automatic classification performance stagnation, recent studies highlight users' continued preference for genre-based recommendations [2]. Genre classification faces subjectivity due to cultural influences, leading to ambiguous definitions, making it challenging to categorize songs [2]. Utilizing audio data, web scraping, and occasionally text or image data, genre classification often benefits from multimodal approaches, outperforming unimodal methods [3]. Current approaches, including deep learning techniques and matrix factorization, are prevalent in this field [4]. This work is an applied statistics project initiated by [Deezer](https://www.deezer.com/), a music platform. The project aims to build a model associating genre labels with each music title in a database using audio signal data and listener-related information, operating within a multilabel classification framework. 

---

##### Collaborators

This work has been done in a group work with [Zineb Bentires](https://www.linkedin.com/in/zineb-bentires-1b9191195/), [Sirine Louati](https://www.linkedin.com/in/sirine-louati-465932179/?originalSubdomain=fr), and [Louise Sirven](https://www.linkedin.com/in/louise-sirven-29066a260/), and under supervision of [Léa Briand](https://www.linkedin.com/in/l%C3%A9a-briand-732291106/) from [Deezer Paris](https://www.deezer.com/) as a part of _Applied statistics_ course at ENSAE Paris.

---

##### References

[1] Koren, Y., Bell, R. et Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8):30–37.

[2] McKay, C. et Fujinaga, I. (2006). Musical genre classification : Is it worth pursuing and how can it be improved ?

[3] Oramas, S., Nieto, O., Barbieri, F. et Serra, X. (2017). Multi-label music genre classification from audio, text, and images using deep features.

[4] Choi, K., Fazekas, G. et Sandler, M. B. (2016). Automatic tagging using deep convolutional neural networks. ArXiv, abs/1606.00298